{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TripAdvisor Rating Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the last part in a three part series.\n",
    "\n",
    "1. Scraping\n",
    "2. <a href=\"http://nbviewer.ipython.org/github/arhee/tripadvisor/blob/master/tripadvisor.ipynb\">Analysis</a>\n",
    "3. <a href=\"http://nbviewer.ipython.org/github/arhee/tripadvisor/blob/master/model.ipynb\">Rating Prediction</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "With the TripAdvisor dataset, I wanted to see if I could build a model to predict a user's rating of an attraction within the computational limits of my laptop.\n",
    "\n",
    "<b>Tools</b>\n",
    "<ul>\n",
    "<li>Modeling done with Python.  Code available <a href=\"https://github.com/arhee/tripadvisor/tree/master/models\">here</a></li>\n",
    "<li>Visualizations done in R</li>\n",
    "</ul>\n",
    "\n",
    "Analysis on the dataset available <a href=\"http://nbviewer.ipython.org/github/arhee/tripadvisor/blob/master/tripadvisor.ipynb\"> here</a>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Framework\n",
    "\n",
    "To begin, let us define the problem as predicting a user's rating of an attraction.  We then define the objective function as minimizing the RMSE:\n",
    "\n",
    "$$\\frac{1}{n}\\sum\\limits_{}^n  (r_{u,i} - \\hat{r}_{u,i})^2,$$\n",
    "\n",
    "where ${r}_{u,i}$ is the rating given by user $u$ for item $i$, and $\\hat{r}_{u,i}$ is the model's estimate.\n",
    "\n",
    "We will use a linear model as:\n",
    "<ul>\n",
    "<li> Linear models have low computational overhead </li>\n",
    "<li> Optimization is guaranteed to find the global minimum </li>\n",
    "<li> Regression models are likely to outperform classification models in RMSE scores </li>\n",
    "</ul>\n",
    "\n",
    "Therefore, the model is in the following format:\n",
    "\n",
    "$$\\hat{r}_{u,i} = \\mu + \\sum_{n\\in\\omega} b_{n},$$\n",
    "\n",
    "where $\\mu$ is the global average rating, and $\\sum_{n\\in\\omega} b_{n}$ is the sum of all the biases $b$ in the set $\\omega$.\n",
    "\n",
    "The corresponding cost function solved via stochastic gradient descent is:\n",
    "\n",
    "$$\\min_{b_{*}}\\sum_{(u,i)\\in\\kappa}({r}_{u,i} - (\\mu + \\Sigma_{n\\in\\omega} b_{n}))^2 + \\lambda\\Sigma_{n\\in\\omega} b_{n}^2),$$\n",
    "\n",
    "where $\\kappa$ is the set of all user reviews, and $\\lambda$ is the regularization parameter.  \n",
    "\n",
    "We will evaluate the performance of the model using k-folds cross-validation with 5 folds to prevent over-fitting and a constant seed value to enable comparison across models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biases\n",
    "\n",
    "The general strategy is to search for and evaluate biases independently to see if they improve upon the global average $\\mu$ or a comparative baseline.  By evaluating biases independently, we can save upon computational time and complexity.\n",
    "\n",
    "However, this approach may find false positives as when two biases that are not truly independent report RMSE improvements.  To address this issue, after collecting all the biases, we will conduct a greedy search to find the best combination of biases that improve the RMSE score in combination.\n",
    "\n",
    "#### Global Average\n",
    "To begin, we evaluate the global average.  A histogram of the TripAdvisor ratings show that it is heavily skewed towards the upper end.  Tourists are very satisfied.  The average rating is a high 4.4/5 stars.\n",
    "\n",
    "<img src=\"figs/ratings_histo.png\" style=\"max-height: 400; max-width: 600px;\">\n",
    "\n",
    "By predicting every rating with the global average with following model:\n",
    "\n",
    "$$\\hat{r}_{u,i} = \\mu$$\n",
    "\n",
    "we obtain a RMSE of 0.903.  We set this as the baseline to improve upon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attraction Bias\n",
    "One obvious possible bias is the attraction itself.  People are likely to rate an attraction close to the attraction average.  With the inclusion of an attraction bias $b_{a}$ in the following model:\n",
    "\n",
    "$$\\hat{r}_{u,i} = \\mu + b_{a}$$\n",
    "\n",
    "we find a considerable RMSE improvement of 0.123 over the global average\n",
    "\n",
    "#### User Bias\n",
    "Another obvious bias is the user. We all have that one grouchy friend who rate items fairly negatively.  With the inclusion of a user bias $b_{u}$, we find a modest RMSE improvement of 0.030 over the global average.\n",
    "\n",
    "<img src=\"figs/reviews_user_histo.png\" style=\"max-height: 400; max-width: 600px;\">\n",
    "\n",
    "The likely cause of a small improvement is that in this dataset, users overwhelmingly only rate a single attraction.  There is noticeable a lack of stickiness; users don't keep rating attractions, it seems to be a one-off endeavour.  Thus, over 97% of users rate less than 5 items.  Without a rich user history, predicting a user's future ratings is difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attraction Group Bias\n",
    "\n",
    "It is plausible that individuals have preferences for categories of attractions.  Someone might be positively biased for attractions that are historical landmarks rather than ecotours. We can term this bias as $b_{u,g}$ for user $u$ and the attraction group $g$.\n",
    "\n",
    "Initially, I investigated a model using the pre-determined groups given on TripAdvisor: Eco Tours, Nature & Wildlife Areas, etc.  Unfortunately, there was no improvement in model prediction.\n",
    "\n",
    "Instead, we can construct our own groups.  By aggregating all the reviews  for each attraction, we construct an attraction \"document\".  These \"documents\" are then cleaned of punctuation, and word stemmed into tokens that are then counted.  This gives a term frequency-inverse document frequency (tf-idf) object which can then be turned into a set of document-specific features with non-negative matrix factorization.  \n",
    "\n",
    "With a set of features describing each document, we can easily cluster the attractions into categories with k-means clustering.  We find that this method of categorizing attractions with the user-group bias $\\hat{r}_{u,i} = \\mu + b_{u,g}$ improves the RMSE by 0.05 over the user bias model: $\\hat{r}_{u,i} = \\mu + b_{u}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language Bias\n",
    "\n",
    "This bias was surprising.  It turns out that reviews written in Japanese were more critical of attractions than any other language.\n",
    "\n",
    "<img src=\"figs/lang_rating.png\" style=\"max-height: 400; max-width: 600px;\">\n",
    "\n",
    "It may be possible that reviews written in Japanese only visited bad attractions.  To determine the improvement we compared $\\hat{r}_{u,i} = \\mu + b_{a}$, the performance of the attraction model, with the following:\n",
    "\n",
    "$$\\hat{r}_{u,i} = \\mu + b_{a} + b_{l},$$\n",
    "\n",
    "where $b_{l}$ is the language correction term.  We do find a small RMSE improvement of 0.02 over the attraction model.  The tiny improvement can be attributed to the fact that reviews written in Japanese are only 3% of all reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal Biases\n",
    "\n",
    "Given that SEAsia has both a rainy and dry season, one would suspect some sort of seasonality for ratings; high ratings during the dry season and poorer ratings during the rainy weather.  However, we did not find any such pattern at the country or city levels.  However, there were some temporal patterns at the attraction level that were consistent throughout 7 years.  With this knowledge, we construct the following model:\n",
    "\n",
    "$$\\hat{r}_{u,i} = \\mu + b_{a,m},$$\n",
    "\n",
    "where $b_{a,m}$ is the bias for attraction $a$ in month $m$ and $a \\in \\tau$ where $\\tau$ is the set of all attractions that show monthly periodicity.  We find a small 0.02 improvement in RMSE over the attraction model: $\\hat{r}_{u,i} = \\mu + b_{a}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model\n",
    "\n",
    "To determine the final model, we institute a greedy search.  By incrementally adding the best performing biases until RMSE improvement ceases, we obtain the following model:\n",
    "\n",
    "$$\\hat{r}_{u,i} = \\mu + b_{a} +  b_{a,m} + b_{u}$$\n",
    "\n",
    "with a total RMSE of 0.762 which is a considerable 16% improvement over the global average of 0.903.  Notably, the small gains from the language bias and the group bias were eliminated leaving behind a relatively simple model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The biggest gains from biases that were rich.  Absent a rich user history, it is hard to predict - the cold start problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
