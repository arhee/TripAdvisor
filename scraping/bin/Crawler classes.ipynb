{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from reviews import Review, ReviewList\n",
    "from bookmark import Bookmark\n",
    "from schema import vietnam_schema\n",
    "import random\n",
    "import json\n",
    "\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "fname = '../tests/test_files/review1.html'\n",
    "with open(fname,'r') as f:\n",
    "    html = f.read()\n",
    "soup = bs(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PageCrawler(object):\n",
    "\n",
    "    def __init__(self, driver):\n",
    "        self.driver = driver\n",
    "        self.base_url = 'http://www.tripadvisor.com'\n",
    "        self.url = None\n",
    "        self.bookmarker = None\n",
    "        self.pagetype = None\n",
    "        self.attrs = {}\n",
    "        \n",
    "    def update_bookmarker(self, new_pos_dict):\n",
    "        self.bookmarker.update(new_pos_dict)\n",
    "\n",
    "    def update_attr(self, new_attrs):\n",
    "        self.attrs.update(new_attrs)\n",
    "    \n",
    "    def listfct(self):\n",
    "        pass\n",
    "    \n",
    "    def nextfct(self):\n",
    "        pass\n",
    "    \n",
    "    def execfct(self):\n",
    "        pass\n",
    "    \n",
    "    def start(self):\n",
    "        while self.url: \n",
    "            self.driver.get(self.url)\n",
    "            time.sleep(random.randint(5,10))\n",
    "            html = self.driver.page_source\n",
    "            soup = bs(html)\n",
    "            div_list = self.listfct(soup)\n",
    "            for item in div_list[:3]:\n",
    "                self.execfct(item)\n",
    "            self.update_bookmarker({self.pagetype:self.url})\n",
    "            self.url = self.nextfct(soup)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ReviewCrawler(PageCrawler):\n",
    "    def __init__(self, driver):\n",
    "        super(ReviewCrawler, self).__init__(driver)\n",
    "        self.review_list = ReviewList('test.db', vietnam_schema, 'vietnam')\n",
    "        self.pagetype = 'review_page'\n",
    "        \n",
    "    def listfct(self, soup):        \n",
    "        tags = soup.find('div',{'id':'REVIEWS'}).findChildren(recursive=False)\n",
    "        reviews = filter(lambda tag: tag.has_attr('id') and 'review_' in tag['id'], tags)\n",
    "        return reviews\n",
    "        \n",
    "    def nextfct(self, soup):\n",
    "        navbar = soup.find('div',{'class': \"unified pagination \"})\n",
    "        return None\n",
    "        try:\n",
    "            return self.base_url + navbar.find(lambda tag: tag.text == 'Next')['href']\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    def execfct(self, review_soup):\n",
    "        review = Review(review_soup, self.attrs)\n",
    "        self.review_list.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ParentCrawler(PageCrawler):\n",
    "    def __init__(self, driver):\n",
    "        super(ParentCrawler, self).__init__(driver)\n",
    "        self.driver = driver\n",
    "        self.pagetype = 'parent_page'\n",
    "#        self.parent_crawler = ParentCrawler(driver)\n",
    "    \n",
    "    def init_child(self):\n",
    "        self.review_crawler = ReviewCrawler(self.driver)\n",
    "    \n",
    "    def set_bookmarker(self, x):\n",
    "        self.bookmarker = x\n",
    "#        self.review_crawler.bookmarker = self.bookmarker\n",
    "        self.review_crawler.bookmarker = x\n",
    "        \n",
    "    def listfct(self, soup):\n",
    "        parent_tags = soup.findAll('div',{'class':'property_title'})\n",
    "        return [(x.a.text, base_url + x.a['href']) for x in parent_tags]\n",
    "    \n",
    "    def execfct(self, item):\n",
    "        self.review_crawler.url = item[1]\n",
    "        #if location\n",
    "        self.review_crawler.update_attr(self.attrs)\n",
    "        self.review_crawler.update_attr({'item_reviewed':item[0]})\n",
    "        #if group\n",
    "        self.review_crawler.start()\n",
    "\n",
    "    def nextfct(self, soup):\n",
    "        tags = soup.find('div',{'id':'pager_top', 'class':'pgLinks'})\n",
    "        try:\n",
    "            next_url = tags.find(lambda tag: tag.name=='a' and tag.text == u\"\\u00BB\")['href']\n",
    "            return self.base_url + next_url\n",
    "        except (TypeError, AttributeError):\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('cities.json', 'r') as f:\n",
    "    lines = f.read()\n",
    "data = json.loads(lines)\n",
    "\n",
    "#['Country', 'ItemReviewed', 'Type', 'ParentGroup', 'Location']\n",
    "\n",
    "base_url = \"http://www.tripadvisor.com\"\n",
    "profile = webdriver.FirefoxProfile(\"/Users/alexrhee/Library/Application Support/Firefox/Profiles/Selenium\")\n",
    "driver = webdriver.Firefox(profile)\n",
    "driver.set_page_load_timeout(15)\n",
    "crawler = ParentCrawler(driver)\n",
    "crawler.init_child()\n",
    "\n",
    "crawler.set_bookmarker(Bookmark('bookmark.json'))\n",
    "\n",
    "base_attr = {'country':'Vietnam', 'type':'Things to do'}\n",
    "crawler.update_attr(base_attr)\n",
    "\n",
    "url = \"http://www.tripadvisor.com/Attractions-g303945-Activities-Ninh_Binh_Ninh_Binh_Province.html\"\n",
    "crawler.url = url\n",
    "crawler.update_attr({'location':'Ninh Binh'})\n",
    "crawler.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bookmark.Bookmark instance at 0x1094eb248>"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instance"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for city in data:\n",
    "#    crawl.url = base_url + city[1]\n",
    "#    crawl.update_attr({'Location':city[0]})\n",
    "#    crawl.start()\n",
    "\n",
    "f = Bookmark('bookmark.json')\n",
    "type(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
